# Creating an API with Express.js

*The process of of aligning (map) reads to a reference and indentify differences between those reads and the reference.*

## Conda Environment ###
We will run the whole process under a specific `conda` environment. 

> **Warning**
>  
> Notice that, since conda is installed for a multi-user environment, we add a local configuration file to handle the searching channels and location of package installation.
>
> In your local home directory (`/home/<user>/`), you should include a `.condarc` configuration file that looks like this:
> ```
> # set the default location for package installation
> pkgs_dirs:
>   - /<HOME>/.conda/pkgs
>channels:
>  - conda-forge
>  - bioconda
>  - defaults
>```
> The file can be generated by using the following commands:
> ```console
> foo@bar:~$ conda config --add channels defaults
> foo@bar:~$ conda config --add channels bioconda
> foo@bar:~$ conda config --add channels conda-forge
> ```
> and adding the line on `pkg_dirs` manually using your preferred text editor.

To create a new conda environment we use 

```console
# to create an environment on your own folder structure
foo@bar:~$ conda create --prefix <HOME>/.conda/envs/<env_name>

# or to create a shared environment
foo@bar:~$ conda create --name <env_name>

# to activate the created environment
foo@bar:~$ conda activate <env_name>
```
where `HOME` is the path to the user's home directory (`/home/<user>/`)

## Reference Genome 

We need to have a target genome against we can actually evaluate the existance of variants. We are currently keeping two different reference genome files, the one included in the 10xGenomics tool Cell Ranger (refdata-gex-GRCh38-2020-A); and one publicly available from NCBI (GCA_000001405.15_GRCh38).  

Genome files are found in the `<HOME>/genome/` folder.

### 10xGenomics Genome

We download the genome directly from 10x genomics website:

```console
foo@bar:~$ wget https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz
```
After downloading and decompressing the file, the FASTA file containing the reference genome can be found in in subfolder `refdata-gex-GRCh38-2020-A/fasta/genome.fa`. We rename the file as `refdata-gex-GRCh38-2020-A.fa` for better identification. 

We compress the file using `bgzip` and generate indexes using the following commands:

```console
# optional use of -k option to keep the input file.
foo@bar:~$ bgzip [-k] refdata-gex-GRCh38-2020-A.fa
refdata-gex-GRCh38-2020-A.fa.gz

foo@bar:~$ samtools faidx refdata-gex-GRCh38-2020-A.fa.gz
refdata-gex-GRCh38-2020-A.fa.gz.fai
refdata-gex-GRCh38-2020-A.fa.gz.gzi
```

### NCBI Genome

`GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz` is a A gzipped file that contains FASTA format sequences for the following:
1. chromosomes from the GRCh38 Primary Assembly unit.
Note: the two PAR regions on chrY have been hard-masked with Ns. The chromosome Y sequence provided therefore has the same coordinates as the GenBank sequence but it is not identical to the GenBank sequence. Similarly, duplicate copies of centromeric arrays and WGS on chromosomes 5, 14, 19, 21 & 22 have been hard-masked with Ns (locations of the unmasked copies are given below). 
2. mitochondrial genome from the GRCh38 non-nuclear assembly unit.
3. unlocalized scaffolds from the GRCh38 Primary Assembly unit.
4. unplaced scaffolds from the GRCh38 Primary Assembly unit.
5. Epstein-Barr virus (EBV) sequence 
Note: The EBV sequence is not part of the genome assembly but is included in the analysis set as a sink for alignment of reads that are often present in sequencing samples.

```console
foo@bar:~$ wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz
```
In order to generate a bgzip compressed version of the file we use the following commands:

```console
foo@bar:~$ zcat GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz | \
...	bgzip > GCA_000001405.15_GRCh38_no_alt_analysis_set.fa.gz
```

`bwa` and `samtools` indexes can be downloaded from the same website, or generated using the following commands.

```console
foo@bar:~$ GEN=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz
foo@bar:~$ bwa index $GEN
foo@bar:~$ sammtools faidx $GEN
```

## Target Preparation

The process for SNP identification is described for the data found in the `<HOME>/Lipid_High/` folder, but it is also applicable for data found in the `<HOME/Lipid_Low>` and `<HOME>/filtered_1` folders.

Original scRNAseq data for the High_Lipid group is found in file `possorted_genome_bam.bam`; a sample of the information provided in this file is as follows:

```console
foo@bar:~$ samtools view possorted_genome_bam.bam | head -n 1
A00587:632:H3FVLDSX3:1:2461:15863:24862	16	chr1	10017	1	90M	*	0	0	CCTAAACCTAACCCTAACCATAACCCTAACCCTAGCCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC	,FFF,,FFF,,,F:,F,:F,,::,F::FFFFFFF,,F,:F,:,F,,::F,,:,,FF:F:F:FFF,FF:FFFFFFFFFFFFFF,FFFFFFF	NH:i:3	HI:i:1	AS:i:82	nM:i:3	RG:Z:Lipid_High:0:1:H3FVLDSX3:1	RE:A:I	xf:i:0	CR:Z:CCCTAACCCCTAACCC	CY:Z:FFFFFFFFFF:FFFFF	UR:Z:CTAACCCCTAAC	UY:Z:FFFFFFFFFFFF	UB:Z:CTAACCCCTAAC
```

### Initial filtering

Of partifcular importance is column indicating values like `xf:i:0`. According to the 10xgenomics definition (https://www.10xgenomics.com/resources/analysis-guides/tutorial-navigating-10x-barcoded-bam-files), in order for a Unique Molecular Identifier (UMI) to be counted, it has to meet a series of specific criteria:

* Have a MAPQ score of 255 (see the STAR manual, section [4.2](https://github.com/alexdobin/STAR/blob/master/doc/STARmanual.pdf)).
* Maps to exactly one gene (as shown in the `GX` tag of the [BAM file](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/bam))
* Overlaps an exon by at least 50% in a way consistent with annotated splice junctions and strand annotation. Records that align to exons will have an `RE:A:E` tag.
* Remove any records with matching UMI and Barcode values that map to different genes.

In Cell Ranger 3, 10x Genomics introduced, `xf`, a bitwise alignment flag and the bits are as follows:

|Name	|Value	|Description|
|-----|-------|-----------|
|CONF_MAPPED | 1 |	The read is confidently mapped to the transcriptome.
|LOW_SUPPORT_UMI |	2 |	This read's (BC, UMI, feature) combination was discarded in favor of a different feature with higher read support.
|GENE_DISCORDANT |	4	| This read pair maps to a discordant pair of genes, and is not treated as a UMI count
|UMI_COUNT|	8	|This read is representative for the molecule and can be treated as a UMI count
|CONF_FEATURE	| 16 | Confidently assigned feature barcode
|FILTERED_TARGET_UMI | 	32 | This read was removed by targeted UMI filtering.|

BAM records that contribute to UMI counting have an `xf:i:25` tag (i.e. CONF_MAPPED + UMI_COUNT + CONF_FEATURE).

It is possible to extract from the original BAM file those records that only contain counted UMIs by filtering accordingly. We do this with the following command:

```console
foo@bar:~$ samtools view -bh possorted_genome_bam.bam \
...	-e '[xf]==25'  \
...	-o possorted_genome_bam_i25.bam

possorted_genome_bam_i25.bam
```

### Donor Filtering

The original data is obtained from a group pooled from different donors. It is important to de-multiplex the contributions from each donor before going any further with the analysis. Fortunately, it was possible to extract the cell barcodes specific to each donor (this de-multiplexation process is described elsewhere). 

Cell barcodes follow the 10xGenomics [Barcoded BAM Tags](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/bam) specification file:


| Tag | Type | Description |
|-----|------|-------------|
|CB|	Z|	Chromium cellular barcode sequence that is error-corrected and confirmed against a list of known-good barcode sequences. For multiplex Fixed RNA Profiling, the cellular barcode is a combination of the 10x GEM Barcode and Probe Barcode sequences.|

Folder `Lipid_High/Lipid_High_barcode_vs_donor/` contains a series of`csv` files, each with the cell barcodes of each donor. To split the contents of the mixed `BAM` file to its donor components, we use the following process:

1. Extract the header of the bam file
2. Filter only the samples that match the list of donor identifiers
3. Concatenate the header and filtered samples
4. Compress the plain text (sam) file back to bam format
5. (Optional) Remove intermediate files

All previous steps are implemented in the following way:

```bash
BASE_PATH='Lipid_High' # or Lipid_Low or filtered_1
BAM_BASE='possorted_genome_bam_i25'
BAM_FILE='possorted_genome_bam_i25.bam'

DONOR='donor_0_'
DONORS_IDS='$BASE_PATH_barcode_vs_donor/donor_0_.csv'

output="$BAM_BASE"_"$DONOR";

samtools view -H $BAM_FILE > SAM_header
samtools view $BAM_FILE | \ 
  LC_ALL=C grep -F -f $1 > $output;
  
cat SAM_header $output > "$output".sam;
  samtools view -bh "$output".sam -o "$output".bam

rm $output;
rm "$output".sam;
rm SAM_header
```

To automatically perform the filtering for each donor, an automated filtering process is implemented in the `filter_BAM_by_donor.sh` script. 

### Calling

Finally, we use `bcftools` to identify variants in the scRNAseq data files of the individual donors.   

```
GENOME='<PATH-TO-GENOME>/refdata-gex-GRCh38-2020-A.fa.gz'
BAM_FILE='possorted_genome_bam_i25_donor_0_.bam'
OUTPUT='possorted_genome_bam_i25_donor_0_.vcf.gz'

bcftools mpileup -f $GENOME \
	$BAM_FILE \
	-q 20 -Q30  | \
	bcftools call -m -v -Oz -o $OUTPUT
```

To do the filtering and calling processes more efficient, we have included a script that filters the original bam file to generate bam files for each of the 24 donors that took part of the initial study: `filter_and_calling_by_donor.sh`. 

The `xf:i:25`, donor filtered bam files are stored in folder `<HOME>/Lipid_High/BAM/possorted_genome_bam_i25_donor{0-23}_.bam`; whilst the variants files resulting from the calling are stored in folder `<HOME>/Lipid_High/variants/possorted_genome_bam_i25_donor_{0-23}_.vcg.gz`.

## Imputation 

We are interested in following list of SNPs:

| Gene | Name | Position (GRC38) |
|------|------|----------|
| PNPLA3 | rs738409 | 22: 43928847 |
| GCKR | rs780094 | 2: 27518370 |
| GCKR | rs1260326 | 2: 27508073 |
| TM6SF2 | rs58542926 | 19:19268740 |

All of these are reported in the study from Kimura et al. As can be shown by  inspecting their list of resulting SNPs (results are cropped for better display). 

```
$ bcftools view -H ISECT_reordered_GTC_all_merged_24samples.vcf.gz | grep -f ../snps.txt 
chr19	19268740	exm1447311	C	T	.	.	GC=0.55;...
chr2	27508073	exm181733	T	C	.	.	GC=0.565;...
chr2	27518370	rs780094;exm-rs780094	T	C	.	.	GC=0.4725;...
chr22	43928847	exm1615904	C	G	.	.	GC=0.53;...
```
where `snps.txt` is a simple list of the positions where the corresponding SNPs are found in the Genome:

```
$ cat snps.txt
43928847
27518370
27508073
19268740
```

But these are not found in the list of SNPs generated in the previous step. It is possible to use script `inspect_variants.sh` to review all individual donor variant files automatically.

In order to explore if it is possible to still infer their presence from the scRNAseq data, we will expand this list using an imputation process.

### Beagle

To actually perform the imputation we will use [`Beagle`](http://faculty.washington.edu/browning/beagle/beagle.html). For details on using the tool, you can check the official [documentation](http://faculty.washington.edu/browning/beagle/beagle_5.4_18Mar22.pdf).

The basic way to run Beagle is as follows:
```
java -Xmx[GB]g -jar ../../scripts/beagle.22Jul22.46e.jar [arguments] 
```
where `[GB]` is an upper bound on the memory pool in Gigabytes; and arguments are a space separated list of parameters vand values eah in the form of `parameter=value`. In particular, we are insterested in providing the the following parameters:

* gt=[file]: The vcf file that contains the genotype samples for the study. In our case, these are the initially reported SNPs for each donor. For example: `reference_variants_possorted_genome_chr20.vcf.gz` ref=ALL.chr20.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes_named.vcf.gz out=test

* ref=[file]

> **_NOTE:_**  Beagle requires java version 8 for its execution. In order to satisfy this requirement we install the corresponding version of `openjdk` in the working conda environment.
> 
> `conda install openjdk=8`


#### Reference Files: 1000genomes project

To perform the imputation process, we need a reference list of SNPs. For this, we will use data from the [1000Genomes project](https://www.internationalgenome.org/). Since we are interested in SNPs located in chromosomes 2, 19 and 22, we will only download the respective lists of SNPs from the 1000genomes ftp server.

The files are found on the [1000genomes ftp website](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/). The files with extension `recalibrated_variants.vcf.gz[.tbi]` include all	variants in Variant Call Format (VCF), together with the index. As Mentioned, we will download files corresponding to chromosomes 2, 19 and 22, that is:

* 20201028_CCDG_14151_B01_GRM_WGS_2020-08-05_chr2.recalibrated_variants.vcf.gz
* 20201028_CCDG_14151_B01_GRM_WGS_2020-08-05_chr19.recalibrated_variants.vcf.gz
* 20201028_CCDG_14151_B01_GRM_WGS_2020-08-05_chr22.recalibrated_variants.vcf.gz

Other references can be also be found for [GRCh37](http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/) and on [gvf format](https://ftp.ensembl.org/pub/release-110/variation/gvf/homo_sapiens/). See the respective websites for more details on these.

<!-- 
ALL.chr2.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz
ALL.chr19.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz
ALL.chr22.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz
homo_sapiens-chr2.gvf.gz
-->

#### Phasing

After phasing, the reference files are named as follows:

* phased_TNmodified_20201028_CCDG_14151_B01_GRM_WGS_2020-08-05_chr22.recalibrated_variants.vcf.gz.vcf.gz


#### Filtering and imputation

Before we can run the imputation ruoutine we need to make sure that both the target and reference files need to contain the same chromosomes in the same order. Since we will be imputing SNPs based on a single chromosome each time, we need to extract the corresponding SNPs from the target files. For this, we use `bfctools` as follows (shown with donor 0 and chr22 as example):

```
bcftools view \
	-r chr22 possorted_genome_bam_i25_donor_0_.vcf.gz' \
	-Oz -o possorted_genome_bam_i25_donor_0_chr22.vcf.gz
``````

Once we have the extracted list of SNPs from the target file and the corresponding reference file, we can run the imputation routine as follows (shown with donor 20 and chr19 as example):

```
java -jar ../../scripts/beagle.22Jul22.46e.jar \
	gt=possorted_genome_bam_i25_donor_20_chr19.vcf.gz \
	ref=references/phased_TNmodified_20201028_CCDG_14151_B01_GRM_WGS_2020-08-05_chr22.recalibrated_variants.vcf.gz \
	out=possorted_genome_bam_i25_donor_20_chr19_imputed
```

For simplicity, the whole process to run the imputation for a given chromosome has been automated in script `filter_and_imputation_by_donor.sh`.
